{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Normalization\n",
    "\n",
    "In machine learning we use large amounts of data to train our models. Some machine learning algorithms may require that the data is *normalized* in order to work correctly. The idea of normalization, also known as *feature scaling*, is to ensure that all the data is on a similar scale, *i.e.* that all the data takes on a similar range of values. For example, we might have a dataset that has values between 0 and 5,000. By normalizing the data we can make the range of values be between 0 and 1.\n",
    "\n",
    "In this lab, you will be performing a different kind of feature scaling known as *mean normalization*. Mean normalization will scale the data, but instead of making the values be between 0 and 1, it will distribute the values evenly in some small interval around zero. For example, if we have a dataset that has values between 0 and 5,000, after mean normalization the range of values will be distributed in some small range around 0, for example between -3 to 3. Because the range of values are distributed evenly around zero, this guarantees that the average (mean) of all elements will be zero. Therefore, when you perform *mean normalization* your data will not only be scaled but it will also have an average of zero. \n",
    "\n",
    "# To Do:\n",
    "\n",
    "You will start by importing NumPy and creating a rank 2 ndarray of random integers between 0 and 5,000 (inclusive) with 1000 rows and 20 columns. This array will simulate a dataset with a wide range of values. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 20)\n"
     ]
    }
   ],
   "source": [
    "# import NumPy into Python\n",
    "import numpy as np\n",
    "\n",
    "# Create a 1000 x 20 ndarray with random integers in the half-open interval [0, 5001).\n",
    "X = np.random.randint(0,5001,size=(1000,20))\n",
    "# print(X)\n",
    "\n",
    "# print the shape of X\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you created the array we will mean normalize it. We will perform mean normalization using the following equation:\n",
    "\n",
    "$\\mbox{Norm_Col}_i = \\frac{\\mbox{Col}_i - \\mu_i}{\\sigma_i}$\n",
    "\n",
    "where $\\mbox{Col}_i$ is the $i$th column of $X$, $\\mu_i$ is average of the values in the $i$th column of $X$, and $\\sigma_i$ is the standard deviation of the values in the $i$th column of $X$. In other words, mean normalization is performed by subtracting from each column of $X$ the average of its values, and then by dividing by the standard deviation of its values. In the space below, you will first calculate the average and standard deviation of each column of $X$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of each cols - [2536.107 2517.731 2441.051 2536.053 2527.438 2458.212 2479.699 2523.24\n",
      " 2438.617 2489.626 2557.096 2534.023 2566.711 2584.17  2465.125 2501.985\n",
      " 2528.517 2492.72  2511.475 2455.179]\n",
      "Standard Deviation of each cols - [1447.2216781  1446.58525177 1455.09308994 1439.00881658 1461.67672355\n",
      " 1454.33644906 1429.36480802 1417.65555563 1440.51941546 1438.2196307\n",
      " 1443.94662186 1426.04860312 1428.04290814 1443.13410988 1415.68538785\n",
      " 1455.13202383 1467.98734385 1444.11637675 1468.77045088 1469.54708225]\n"
     ]
    }
   ],
   "source": [
    "# Average of the values in each column of X\n",
    "ave_cols = np.mean(X,axis=0)\n",
    "print(f\"Average of each cols - {ave_cols}\")\n",
    "# Standard Deviation of the values in each column of X\n",
    "std_cols =np.std(X,axis=0)\n",
    "print(f\"Standard Deviation of each cols - {std_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have done the above calculations correctly, then `ave_cols` and `std_cols`, should both be vectors with shape `(20,)` since $X$ has 20 columns. You can verify this by filling the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20,)\n",
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of ave_cols\n",
    "print(ave_cols.shape)\n",
    "\n",
    "\n",
    "# Print the shape of std_cols\n",
    "print(std_cols.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now take advantage of Broadcasting to calculate the mean normalized version of $X$ in just one line of code using the equation above. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.44990136 -0.38209362 -1.51196581 ... -0.60986775 -0.14670434\n",
      "   1.07708084]\n",
      " [ 0.74411061 -1.740465    0.27142525 ... -0.5198473  -0.78669543\n",
      "  -0.93850617]\n",
      " [-0.10441179  1.25555614 -0.85977386 ... -0.93532628  0.37005442\n",
      "   0.53473687]\n",
      " ...\n",
      " [-1.58656206 -1.45703891  0.05356977 ...  0.64695617  1.02706655\n",
      "   1.5153111 ]\n",
      " [-0.76844275 -1.41417936 -1.14085553 ... -0.26640512 -0.27878761\n",
      "  -0.46897375]\n",
      " [ 1.12276718 -0.43393986  1.44592055 ...  0.65872807 -0.07862018\n",
      "  -0.4145352 ]]\n"
     ]
    }
   ],
   "source": [
    "# Mean normalize X\n",
    "X_norm = (X - ave_cols) /std_cols\n",
    "print(X_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have performed the mean normalization correctly, then the average of all the elements in $X_{\\tiny{\\mbox{norm}}}$ should be close to zero, and they should be evenly distributed in some small interval around zero. You can verify this by filing the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of all the values of X_norm :  -2.842170943040401e-18\n",
      "Average of the minimum value in each column of X_norm :  -1.7303871791356724\n",
      "Average of the maximum value in each column of X_norm :  1.722599520307113\n"
     ]
    }
   ],
   "source": [
    "# Print the average of all the values of X_norm\n",
    "print(f\"Average of all the values of X_norm :  {X_norm.mean()}\")\n",
    "\n",
    "# Print the average of the minimum value in each column of X_norm\n",
    "print(f\"Average of the minimum value in each column of X_norm :  {X_norm.min(axis=0).mean()}\")\n",
    "\n",
    "# Print the average of the maximum value in each column of X_norm\n",
    "print(f\"Average of the maximum value in each column of X_norm :  {X_norm.max(axis=0).mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should note that since $X$ was created using random integers, the above values will vary. \n",
    "\n",
    "# Data Separation\n",
    "\n",
    "After the data has been mean normalized, it is customary in machine learnig to split our dataset into three sets:\n",
    "\n",
    "1. A Training Set\n",
    "2. A Cross Validation Set\n",
    "3. A Test Set\n",
    "\n",
    "The dataset is usually divided such that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. \n",
    "\n",
    "In this part of the lab you will separate `X_norm` into a Training Set, Cross Validation Set, and a Test Set. Each data set will contain rows of `X_norm` chosen at random, making sure that we don't pick the same row twice. This will guarantee that all the rows of `X_norm` are chosen and randomly distributed among the three new sets.\n",
    "\n",
    "You will start by creating a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`. You can do this by using the `np.random.permutation()` function. The `np.random.permutation(N)` function creates a random permutation of integers from 0 to `N - 1`. Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 0, 1, 2])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We create a random permutation of integers 0 to 4\n",
    "np.random.permutation(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do\n",
    "\n",
    "In the space below create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`. You can do this in one line of code by extracting the number of rows of `X_norm` using the `shape` attribute and then passing it to the  `np.random.permutation()` function. Remember the `shape` attribute returns a tuple with two numbers in the form `(rows,columns)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "[ 48 195 508 128 444 493 369 420 976 571 835  47 731 140 482 395 627  22\n",
      " 449 674 512 470 380 333   4 631 328 649 950  58 106 389  24 530 264 689\n",
      " 672 870 407 719  69  33 787 662 592 396 743 721 342 992 284 892 596 745\n",
      " 961 372 338 692 144 257 223 644 357 101 240 898 336 991 650 415 135 329\n",
      " 839 791 688  17 818 737  39 993 325   5 186 557 926 751 679  43 318   3\n",
      " 590  16 621 893 400 570  85 256 311 939 901 359 711 513 614 833 102 722\n",
      " 966 708 406  66  73  88 378 365 347 648 757 916  36  26 155  61 373 288\n",
      "  19 558 109 304 702 654 651 663 481 165 853 450 254 414 174 435 233 807\n",
      " 387 739 716 620 604 520  71 391 547 439 483 799 285 881 612 734 220 877\n",
      "  78 377   6 236 684 600 813 419 575 646 912 828 984 125 327 277 628 937\n",
      "  68 949 758 946 495 769 868 823 748 162 732 459 932 691 999 468 972 536\n",
      " 562 902 436 473  51 841 475 446 776 804 848 956 591 831 521 671 434 790\n",
      " 138 738 774 761 467 816 735 802 640 145 385 888 977 921 572 465 343 609\n",
      " 266 783 197 657 477  84 858 201 489 532 855 228 568  31 863 103 859  96\n",
      " 955 619 788 227 630 244 587 528 418 713 642 641 814  10 278 179  32 666\n",
      " 599 825 826 965 954  46 279  67 801  81 394 756 509 832 309 595 353 785\n",
      "  65 911 146 480 840 829  86  79 846 730 957 126 479 212 205 539 298 263\n",
      " 324 729 119  77 973  20 478 216 960 971 472 617 561 882 490 935   2 127\n",
      " 696 268 685 541 771 374 149 431 618 210 247 746 441 522 793 111 940 412\n",
      " 878 363 635 636  35 883 108 404 303 865 962 990 134 538 376 131 301 542\n",
      " 616 625 362 104 849 933  60 280 824 922 543 440 579 222 209 880 191 887\n",
      " 397 871 585 510 728 947  95   7 177 894 129 487 891 564 602 455 243 425\n",
      " 332 231 773 237 208 517  41   9 526 500 819 451 903   1 282 624 909 552\n",
      " 294 230 505 611 502 908 664 498  93 924 540 323 206 310 770 941 629 114\n",
      " 862 141 433 805 466 462 190 170 248 200  25 633 501 246 952 948 188 809\n",
      " 569 345 218 518 856 290 925 384 293 274 890  40 733 548  38 811 700 797\n",
      " 598 742 677 781 113 726 779 904 897 953  90 847 638 800 364 453 944 297\n",
      " 777 344 780 189 454 503 447 460 194 185 316 229 850 706 750 308 461 187\n",
      " 680 597 792 346 778 988 886 577  50 156 426 299 606 133 682 427 996 714\n",
      " 900 560 652   0 392 307 211 705 645 931 351 300  92 214 820 159  18  54\n",
      " 317 860 428 350  13 968 822 873 507 175 615 753 951 938 445 723 958 356\n",
      " 117 143 273 287 180 112 269 834 432 997  57 998 725 549 736 795 499 314\n",
      " 120 565 494 366 661 319 331 775  42 784 251 261 160  75 715 766 166  87\n",
      " 643 752 118 838  91 100 281 995 529 381 163 727 945 252  82 910  12 424\n",
      " 884 533 867 580 525 747 836 241 354 476 136  59 232 511 253 305 553  83\n",
      " 698 239 586  62 889 914 286 854 885 994 906 610 852 154 183 754 383 655\n",
      " 683 913 255 613  21 554 504 808 605 789 340 593 803  11 875 172 917 740\n",
      " 759 693 724 225 313 361 537 335 806 622 589 423 842 658 393 291 879 923\n",
      " 139 399 471 653 289 535 786 905 272 422 709 764 918 485 821 235 697  64\n",
      " 982 895 594 936 458 275 545 173 302 581 763 259 322 710 276 718  89 704\n",
      " 981 794 152 226 815 121 107 678 368 405 876 767 942 167 442 320 258 915\n",
      " 168 370  23 699 919  29 339 687 576 741 980 668 559 762  52 673 907 388\n",
      " 213 851 262 969 717 686  63 647 845 626 588 744 182 634 196  80 546 563\n",
      " 315 632 178 755   8 105 515 411 556 695 464 796 601 448 367  56 124 123\n",
      "  72 896 574 375 148 623 989 360 830 122 669 349  34 639  55 242 516 810\n",
      " 270 203 676 452 928 401 964 874  99 798 457 864 469  74 978 551 267 979\n",
      " 224 656  30 437 857 429 583 607 164 930 959 358 986 844 974 463 334 943\n",
      " 176 184 265 207 963 872  94 550 749  14 566 321 694  98 153 137 514 390\n",
      " 934 927 929 151 341 667 116  15 379 484 584 843 523 403 866 519 161 920\n",
      " 567 438 544 312 555 660 772 869 430 608 295 408 204 703 488 486 157 837\n",
      " 768 491  27 202 296 707 970 492 456 221  97 192 250 827 234 967 171 861\n",
      " 496 474 215  76 193  53 169 760 899 782 497 371  28 271 975 217 812 245\n",
      " 110 817 130 199 306  45 410 181 147 386 158 260  37 115 665 712 417 573\n",
      " 603 348 421 219 398 720 238 355 681 150 582 578 524 326 765 527 249 690\n",
      " 337 534 987 142 985 670  70 659 292  44 330 983 416 443 402 132 382 506\n",
      " 413 409  49 701 531 352 198 675 283 637]\n"
     ]
    }
   ],
   "source": [
    "# Create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`\n",
    "row_indices = np.random.permutation(len(X_norm))  # creates  one D array \n",
    "# print(row_indices)\n",
    "print(X_norm.shape[0])\n",
    "row_indices = np.random.permutation(X_norm.shape[0])\n",
    "print(row_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can create the three datasets using the `row_indices` ndarray to select the rows that will go into each dataset. Rememeber that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. Each set requires just one line of code to create. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600\n",
      "800\n",
      "[[ 0.93205693 -1.52685851  1.01708201 ... -0.2075456   0.50622274\n",
      "  -1.42505063]\n",
      " [-0.41949828  0.54146066 -1.10511899 ...  0.2806422  -1.08149983\n",
      "  -0.18249092]\n",
      " [-0.62195517 -0.9980269   1.14422164 ...  1.31172254  0.74111308\n",
      "  -0.52069036]\n",
      " ...\n",
      " [-1.35162915  0.97766032  0.24805904 ...  1.4647573  -1.10328677\n",
      "  -0.53293903]\n",
      " [ 1.6057616  -0.33716022 -0.1258002  ...  0.54170149  0.98281185\n",
      "  -1.44342364]\n",
      " [ 1.44476346  1.27560335 -0.64741631 ...  0.26817783 -1.20609384\n",
      "  -0.48802724]]\n"
     ]
    }
   ],
   "source": [
    "# Make any necessary calculations.\n",
    "# You can save your calculations into variables to use later.\n",
    "sixty = int(len(X_norm)* 0.6) \n",
    "print(sixty)\n",
    "\n",
    "eighty = int(len(X_norm)* 0.8) \n",
    "print(eighty)\n",
    "\n",
    "# Create a Training Set\n",
    "X_train = X_norm[row_indices[:sixty],:]\n",
    "print(X_train)                 \n",
    "\n",
    "# Create a Cross Validation Set\n",
    "X_crossVal = X_norm[row_indices[sixty:eighty],:]\n",
    "\n",
    "# Create a Test Set\n",
    "X_test = X_norm[row_indices[eighty:],:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you performed the above calculations correctly, then `X_tain` should have 600 rows and 20 columns, `X_crossVal` should have 200 rows and 20 columns, and `X_test` should have 200 rows and 20 columns. You can verify this by filling the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 20)\n",
      "(200, 20)\n",
      "(200, 20)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of X_train\n",
    "print(X_train.shape)                 \n",
    "\n",
    "# Print the shape of X_crossVal\n",
    "print(X_crossVal.shape)  \n",
    "\n",
    "\n",
    "# Print the shape of X_test\n",
    "print(X_test.shape)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
